# Kali OSINT Social Media Scraper Platform

A comprehensive, enterprise-grade Open Source Intelligence (OSINT) investigation platform designed for professional security research, law enforcement, and threat intelligence operations. This platform provides advanced social media scraping, real-time threat analysis, network intelligence, and automated report generation with a modern, responsive web interface.

## üöÄ Core Features

### üîç Advanced Investigation Capabilities
- **Multi-Platform Social Media Scraping**: Real-time scraping across Twitter, Instagram, Reddit, GitHub, LinkedIn, Facebook, YouTube, TikTok, Telegram, and Discord
- **Comprehensive Domain Intelligence**: Deep domain analysis including subdomain enumeration, DNS records, WHOIS data, SSL certificates, and technology detection
- **Network Analysis & Visualization**: Entity relationship mapping, community detection, and interactive network graphs
- **Threat Assessment Engine**: AI-powered threat scoring, anomaly detection, and risk analysis
- **Dark Web Intelligence**: Tor network scanning and dark web entity discovery (experimental)

### üõ°Ô∏è Security & Intelligence Features
- **Real-time Threat Detection**: Automated threat scoring with configurable thresholds
- **Anomaly Detection**: Machine learning-based pattern recognition and behavioral analysis
- **Entity Resolution**: Cross-platform entity correlation and relationship mapping
- **Intelligence Fusion**: Correlate data across multiple sources and platforms
- **Pattern Analysis**: Advanced pattern recognition for threat indicators

### üìä Analytics & Reporting
- **Interactive Dashboard**: Real-time monitoring with live statistics and progress tracking
- **Advanced Analytics**: Network graphs, timeline analysis, and geographic mapping
- **Automated Report Generation**: PDF, CSV, JSON, and HTML report formats
- **Export Capabilities**: Comprehensive data export with customizable formats
- **Progress Tracking**: Real-time investigation progress with estimated completion times

### üé® Modern Web Interface
- **Responsive Design**: Works seamlessly on desktop, tablet, and mobile devices
- **Dark Mode Support**: Toggle between light and dark themes
- **Real-time Updates**: WebSocket-based live updates and notifications
- **Interactive Visualizations**: Charts, graphs, and network diagrams
- **Professional UI/UX**: Clean, modern interface with cyberpunk aesthetics

## üèóÔ∏è Technical Architecture

### Backend Stack
- **FastAPI**: High-performance async web framework
- **SQLAlchemy**: Advanced ORM with PostgreSQL/SQLite support
- **Celery**: Distributed task queue for background processing
- **Redis**: Caching and session management
- **Playwright**: Advanced browser automation for web scraping
- **Alembic**: Database migration management

### Frontend Stack
- **React 18**: Latest React with concurrent features
- **TypeScript**: Type-safe development
- **Tailwind CSS**: Utility-first CSS framework
- **React Router**: Client-side routing
- **React Query**: Server state management
- **Chart.js**: Interactive data visualizations

### AI/ML Capabilities
- **Machine Learning Intelligence**: Advanced ML models for threat prediction
- **Natural Language Processing**: Sentiment analysis and text classification
- **Anomaly Detection**: Behavioral pattern recognition
- **Entity Resolution**: Cross-platform entity correlation
- **Threat Classification**: Automated threat level assessment

## üìã System Requirements

### Minimum Requirements
- **Python**: 3.9+ (recommended 3.11+)
- **Node.js**: 16+ (for frontend development)
- **PostgreSQL**: 12+ (recommended) or SQLite
- **Redis**: 6+ (for background tasks)
- **Memory**: 4GB RAM minimum, 8GB+ recommended
- **Storage**: 10GB+ available space

### Recommended Setup
- **CPU**: 4+ cores
- **Memory**: 16GB+ RAM
- **Storage**: SSD with 50GB+ available space
- **Network**: Stable internet connection for scraping

## üõ†Ô∏è Installation & Setup

### 1. Clone the Repository
```bash
git clone <repository-url>
cd KaliSocialMediaScraper
```

### 2. Install Python Dependencies
```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 3. Install Playwright Browsers
```bash
playwright install
```

### 4. Setup Database
```bash
# Run database migrations
alembic upgrade head

# Initialize database
python -m app.utils.db_init
```

### 5. Install Frontend Dependencies
```bash
cd frontend
npm install
```

### 6. Configure Environment
```bash
# Copy environment template
cp .env.example .env

# Edit configuration
nano .env
```

## üöÄ Quick Start

### Automated Startup (Recommended)
```bash
# Run the automated startup script
python start_platform.py
```

This script will:
- Check and install missing dependencies
- Setup the database and run migrations
- Install Playwright browsers
- Start the backend server (FastAPI)
- Start the frontend development server (React)

### Manual Startup

#### Backend Server
```bash
# Start the FastAPI backend
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

#### Frontend Server
```bash
# Start the React frontend
cd frontend
npm start
```

## üåê Access Points

- **Frontend UI**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **API Documentation**: http://localhost:8000/docs
- **Interactive API Docs**: http://localhost:8000/redoc
- **Health Check**: http://localhost:8000/health

## üîß Configuration

### Environment Variables
Create a `.env` file in the root directory:

```env
# Database Configuration
DATABASE_URL=postgresql://user:password@localhost/kali_osint
DATABASE_TEST_URL=sqlite:///./kali_osint_test.db

# Redis Configuration
REDIS_URL=redis://localhost:6379
REDIS_HOST=localhost
REDIS_PORT=6379

# Security Settings
SECRET_KEY=your-secret-key-change-in-production
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# API Settings
ALLOWED_HOSTS=["http://localhost:3000", "http://localhost:8000"]
BACKEND_CORS_ORIGINS=["http://localhost:3000", "http://localhost:8000"]

# Scraping Configuration
SCRAPING_DELAY=1.0
MAX_CONCURRENT_REQUESTS=16
USER_AGENT_ROTATION=true
REQUEST_TIMEOUT=30
PROXY_ROTATION=false

# Rate Limiting
RATE_LIMIT_ENABLED=true
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=3600

# Analysis Settings
MAX_ANALYSIS_DEPTH=3
NETWORK_GRAPH_MAX_NODES=1000
THREAT_SCORE_THRESHOLD=0.7
THREAT_INTELLIGENCE_ENABLED=true
ANOMALY_DETECTION_ENABLED=true

# Optional API Keys (for enhanced functionality)
SHODAN_API_KEY=your-shodan-api-key
CENSYS_API_ID=your-censys-api-id
CENSYS_API_SECRET=your-censys-api-secret
VIRUSTOTAL_API_KEY=your-virustotal-api-key
```

### Settings Management
The platform includes a comprehensive settings management system accessible via:

- **API Endpoints**: `/api/v1/settings`
- **Frontend UI**: Settings page in the web interface

Settings categories:
- **Scraping**: User agent rotation, proxy settings, delays, rate limits
- **Security**: Threat detection thresholds, anomaly detection, auto-blocking
- **Analysis**: Analysis depth, network graph limits, timeline settings
- **Notifications**: Email and webhook notifications
- **Export**: Report formats and export options

## üìä Usage Examples

### 1. Create a Comprehensive Investigation
```python
import requests

# Create investigation
investigation_data = {
    "target_type": "username",
    "target_value": "target_user",
    "analysis_depth": "comprehensive",
    "platforms": ["github", "twitter", "instagram", "linkedin"],
    "include_network_analysis": True,
    "include_timeline_analysis": True,
    "include_threat_assessment": True,
    "analysis_options": {
        "max_depth": 3,
        "include_relationships": True,
        "threat_threshold": 0.7
    }
}

response = requests.post("http://localhost:8000/api/v1/investigations", json=investigation_data)
investigation_id = response.json()["id"]
```

### 2. Domain Intelligence Analysis
```python
# Analyze domain with comprehensive options
domain_data = {
    "domain": "example.com",
    "include_subdomains": True,
    "include_dns": True,
    "include_whois": True,
    "include_ssl": True,
    "include_technologies": True,
    "include_threat_analysis": True
}

response = requests.post("http://localhost:8000/api/v1/analysis/domain", json=domain_data)
```

### 3. Generate Comprehensive Report
```python
# Generate PDF report with all findings
report_data = {
    "investigation_id": investigation_id,
    "report_type": "pdf",
    "include_network_graphs": True,
    "include_timeline": True,
    "include_threat_assessment": True,
    "include_raw_data": False
}

response = requests.post("http://localhost:8000/api/v1/exports/investigation/{investigation_id}/pdf", json=report_data)
```

### 4. Real-time Monitoring
```python
# Monitor investigation progress
import websockets
import asyncio

async def monitor_investigation(investigation_id):
    async with websockets.connect(f"ws://localhost:8000/ws") as websocket:
        while True:
            message = await websocket.recv()
            data = json.loads(message)
            print(f"Progress: {data.get('progress', 0)}%")
```

## üß™ Testing & Validation

### Run Comprehensive Tests
```bash
# Test all functionality including real scraping
python test_real_functionality.py
```

This comprehensive test suite validates:
- API health and connectivity
- Real social media scraping (GitHub, Twitter, etc.)
- Domain intelligence and analysis
- Threat assessment and scoring
- Report generation and export
- Settings management
- Database operations

### Test Individual Components
```bash
# Test domain analyzer specifically
python test_domain_analyzer.py

# Test general functionality
python test_functionality.py
```

### Frontend Testing
```bash
cd frontend
npm test
```

## üìÅ Project Structure

```
KaliSocialMediaScraper/
‚îú‚îÄ‚îÄ app/                          # Backend application
‚îÇ   ‚îú‚îÄ‚îÄ api/                      # API endpoints and routing
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ v1/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ endpoints/        # Individual endpoint modules
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ api.py           # Main API router
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ docs.py          # API documentation
‚îÇ   ‚îú‚îÄ‚îÄ core/                     # Core configuration and utilities
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py            # Application settings
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py          # Database configuration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth.py              # Authentication utilities
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ celery_app.py        # Background task configuration
‚îÇ   ‚îú‚îÄ‚îÄ models/                   # Database models and schemas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py          # SQLAlchemy models
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py           # Pydantic schemas
‚îÇ   ‚îú‚îÄ‚îÄ repositories/             # Data access layer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_repository.py   # Base repository pattern
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ investigation_repository.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ social_media_repository.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ user_repository.py
‚îÇ   ‚îú‚îÄ‚îÄ services/                 # Business logic and external services
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ social_media_scraper.py    # Multi-platform scraping
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ github_scraper.py          # GitHub-specific scraping
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ domain_analyzer.py         # Domain intelligence
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ network_analyzer.py        # Network analysis
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ threat_analyzer.py         # Threat assessment
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ml_intelligence.py         # Machine learning
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ anomaly_detector.py        # Anomaly detection
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pattern_analyzer.py        # Pattern recognition
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dark_web_intelligence.py   # Dark web scanning
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ intelligence_engine.py     # Intelligence fusion
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ entity_resolver.py         # Entity resolution
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ threat_correlator.py       # Threat correlation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ proxy_rotator.py           # Proxy management
‚îÇ   ‚îî‚îÄ‚îÄ tasks/                    # Background task processing
‚îÇ       ‚îú‚îÄ‚îÄ analysis_tasks.py     # Analysis background tasks
‚îÇ       ‚îú‚îÄ‚îÄ investigation_tasks.py # Investigation processing
‚îÇ       ‚îú‚îÄ‚îÄ scraping_tasks.py     # Scraping background tasks
‚îÇ       ‚îú‚îÄ‚îÄ report_tasks.py       # Report generation tasks
‚îÇ       ‚îî‚îÄ‚îÄ maintenance_tasks.py  # System maintenance
‚îú‚îÄ‚îÄ frontend/                     # React frontend application
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/           # Reusable React components
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Layout.tsx       # Main layout component
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ RealTimeDashboard.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/                # Page components
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dashboard.tsx    # Main dashboard
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Investigations.tsx # Investigation management
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SocialMedia.tsx  # Social media analysis
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Analysis.tsx     # Advanced analytics
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Reports.tsx      # Report management
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Settings.tsx     # Platform settings
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/             # API service layer
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api.ts           # Base API client
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ investigations.ts # Investigation API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hooks/                # Custom React hooks
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ useDashboardData.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ useRealTimeData.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ styles/               # Styling and CSS
‚îÇ   ‚îú‚îÄ‚îÄ public/                   # Static assets
‚îÇ   ‚îî‚îÄ‚îÄ package.json              # Frontend dependencies
‚îú‚îÄ‚îÄ alembic/                      # Database migrations
‚îÇ   ‚îú‚îÄ‚îÄ versions/                 # Migration files
‚îÇ   ‚îî‚îÄ‚îÄ env.py                    # Migration environment
‚îú‚îÄ‚îÄ static/                       # Static files served by FastAPI
‚îú‚îÄ‚îÄ reports/                      # Generated reports storage
‚îú‚îÄ‚îÄ logs/                         # Application logs
‚îú‚îÄ‚îÄ data/                         # Data storage
‚îú‚îÄ‚îÄ docs/                         # Documentation
‚îú‚îÄ‚îÄ tests/                        # Test files
‚îú‚îÄ‚îÄ requirements.txt              # Python dependencies
‚îú‚îÄ‚îÄ start_platform.py            # Automated startup script
‚îú‚îÄ‚îÄ docker-compose.yml           # Docker configuration
‚îî‚îÄ‚îÄ README.md                    # This file
```

## üîç API Endpoints

### Investigations
- `POST /api/v1/investigations` - Create new investigation
- `GET /api/v1/investigations` - List all investigations
- `GET /api/v1/investigations/{id}` - Get investigation details
- `PUT /api/v1/investigations/{id}` - Update investigation
- `DELETE /api/v1/investigations/{id}` - Delete investigation
- `GET /api/v1/investigations/{id}/status` - Get investigation status
- `GET /api/v1/investigations/{id}/findings` - Get investigation findings

### Social Media Analysis
- `POST /api/v1/social-media/scrape` - Scrape social media profiles
- `GET /api/v1/social-media/search` - Search social media content
- `GET /api/v1/social-media/platforms` - Get available platforms
- `POST /api/v1/social-media/analyze` - Analyze social media data

### Domain Intelligence
- `POST /api/v1/analysis/domain` - Analyze domain comprehensively
- `GET /api/v1/analysis/domain/{domain}/subdomains` - Get subdomains
- `GET /api/v1/analysis/domain/{domain}/dns` - Get DNS records
- `GET /api/v1/analysis/domain/{domain}/whois` - Get WHOIS data
- `GET /api/v1/analysis/domain/{domain}/ssl` - Get SSL certificate

### Network Analysis
- `GET /api/v1/analysis/network/{entity_id}` - Get network graph
- `POST /api/v1/analysis/network/generate` - Generate network analysis
- `GET /api/v1/analysis/timeline/{entity_id}` - Get timeline data
- `POST /api/v1/analysis/timeline/generate` - Generate timeline

### Threat Intelligence
- `POST /api/v1/analysis/threat` - Analyze threat level
- `GET /api/v1/analysis/threat/indicators` - Get threat indicators
- `POST /api/v1/analysis/anomaly` - Detect anomalies
- `GET /api/v1/analysis/anomaly/patterns` - Get anomaly patterns

### Reports & Exports
- `POST /api/v1/exports/investigation/{id}/pdf` - Generate PDF report
- `POST /api/v1/exports/investigation/{id}/csv` - Generate CSV export
- `POST /api/v1/exports/investigation/{id}/json` - Generate JSON export
- `GET /api/v1/exports/reports` - List generated reports
- `GET /api/v1/exports/reports/{id}/download` - Download report

### Dashboard & Analytics
- `GET /api/v1/dashboard/stats` - Get dashboard statistics
- `GET /api/v1/dashboard/recent` - Get recent activity
- `GET /api/v1/dashboard/threats` - Get threat summary
- `GET /api/v1/dashboard/performance` - Get system performance

### Settings Management
- `GET /api/v1/settings` - Get all platform settings
- `PUT /api/v1/settings/{category}` - Update settings category
- `POST /api/v1/settings/reset` - Reset settings to defaults
- `GET /api/v1/settings/categories` - Get settings categories

### System Health
- `GET /api/v1/health` - System health check
- `GET /api/v1/health/services` - Service status
- `GET /api/v1/health/metrics` - System metrics

### Real-time Updates
- `WS /ws` - WebSocket endpoint for real-time updates

## üõ°Ô∏è Security Features

### Platform Security
- **Rate Limiting**: Configurable request limits per endpoint
- **Input Validation**: Comprehensive input sanitization and validation
- **Error Handling**: Secure error handling without information leakage
- **Authentication**: JWT-based authentication system
- **Authorization**: Role-based access control

### Scraping Security
- **Proxy Support**: Rotating proxy support for anonymity
- **User Agent Rotation**: Automatic user agent rotation
- **Request Throttling**: Configurable delays between requests
- **SSL Verification**: Configurable SSL certificate verification
- **Timeout Management**: Request timeout configuration

### Threat Intelligence
- **Threat Detection**: AI-powered threat assessment
- **Anomaly Detection**: Automated anomaly identification
- **Pattern Recognition**: Advanced pattern analysis
- **Risk Scoring**: Configurable risk assessment thresholds
- **Intelligence Fusion**: Cross-source threat correlation

## üìà Performance & Scalability

### Performance Optimizations
- **Asynchronous Processing**: Non-blocking operations throughout
- **Background Tasks**: Celery-based task queue for heavy operations
- **Caching**: Redis-based caching for frequently accessed data
- **Connection Pooling**: Efficient database connection management
- **Memory Management**: Optimized memory usage and garbage collection

### Scalability Features
- **Horizontal Scaling**: Support for multiple backend instances
- **Load Balancing**: Ready for load balancer integration
- **Database Optimization**: Efficient queries and indexing
- **Task Distribution**: Distributed task processing
- **Resource Management**: Configurable resource limits

### Monitoring & Metrics
- **Health Checks**: Comprehensive system health monitoring
- **Performance Metrics**: Real-time performance tracking
- **Error Tracking**: Detailed error logging and monitoring
- **Resource Usage**: Memory, CPU, and network monitoring
- **Custom Metrics**: Application-specific metrics collection

## ü§ù Contributing

We welcome contributions from the security research community!

### Development Setup
1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Make your changes with proper testing
4. Add tests for new functionality
5. Ensure all tests pass: `python test_real_functionality.py`
6. Submit a pull request

### Code Standards
- **Python**: Follow PEP 8 style guidelines
- **TypeScript**: Use strict TypeScript configuration
- **Testing**: Maintain high test coverage
- **Documentation**: Update documentation for new features
- **Security**: Follow security best practices

### Testing Guidelines
- **Unit Tests**: Test individual components
- **Integration Tests**: Test API endpoints
- **End-to-End Tests**: Test complete workflows
- **Performance Tests**: Test under load
- **Security Tests**: Test security features

## üìÑ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ‚ö†Ô∏è Legal Disclaimer

This platform is designed for **legitimate OSINT research, security research, and law enforcement purposes only**. Users are responsible for:

- Complying with all applicable laws and regulations
- Respecting terms of service of target platforms
- Obtaining proper authorization for investigations
- Using the platform ethically and responsibly
- Not using the platform for malicious purposes

The developers are not responsible for misuse of this platform.

## üÜò Support & Documentation

### Getting Help
- **API Documentation**: Interactive docs at `/docs`
- **Code Examples**: Review test files for usage examples
- **Issue Tracking**: Report bugs and feature requests on GitHub
- **Community**: Join our security research community

### Documentation
- **API Reference**: Complete API documentation
- **User Guide**: Step-by-step usage instructions
- **Developer Guide**: Development and contribution guidelines
- **Security Guide**: Security best practices and recommendations

### Troubleshooting
- **Health Checks**: Use `/health` endpoint for system status
- **Logs**: Check application logs for detailed error information
- **Testing**: Run test suite to validate functionality
- **Configuration**: Verify environment variables and settings

## üîÑ Recent Updates

### Latest Features (v1.0.0)
- **Advanced ML Intelligence**: Enhanced machine learning capabilities
- **Dark Web Intelligence**: Tor network scanning capabilities
- **Real-time Dashboard**: Live monitoring and progress tracking
- **Enhanced UI/UX**: Modern, responsive interface with dark mode
- **Comprehensive Testing**: Full test suite with real functionality validation
- **Performance Optimizations**: Improved scalability and performance
- **Security Enhancements**: Advanced threat detection and anomaly analysis
- **Export Capabilities**: Multiple report formats and export options

### Planned Features
- **Additional Platforms**: Support for more social media platforms
- **Advanced Analytics**: Enhanced visualization and analysis tools
- **Mobile App**: Native mobile application
- **API Enhancements**: Additional endpoints and capabilities
- **Performance Improvements**: Further optimization and scaling

---

**Built with ‚ù§Ô∏è for the security research community** 